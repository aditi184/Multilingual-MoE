# Tango settings file
#
# See https://ai2-tango.readthedocs.io/en/latest/api/settings.html
# for a list and description of all available fields.

workspace:
  type: "gs"
  workspace: "akshitab-eval-test"
  project: "ai2-allennlp"

# Define the executor to use (how steps will be run).
executor:
  type: beaker
  beaker_workspace: ai2/akshitab_llm
  # TODO: uncomment once the beaker image creation issue is fixed.
  # beaker_image: akshitab/eval-streamline-image
  venv_name: base
  scheduler:
    type: simple
    priority: preemptible
    clusters:
      # Add your own team's clusters here ðŸ‘‡
      - ai2/general-cirrascale
      - ai2/allennlp-cirrascale
  allow_dirty: true
  install_cmd: "pip install --upgrade pip; pip install -e .; pip install -r evaluation/requirements.txt;"
  datasets:
    - source:
        host_path: /net/nfs.cirrascale
      mount_path: /net/nfs.cirrascale
  env_vars:
    - name: "HF_DATASETS_CACHE"
      value: "/net/nfs.cirrascale/aristo/oyvindt/hf_datasets_cache"
    # This is the location for downloading models and making them HF-compatible (nfs for accessibility across steps).
    - name: "GLOBAL_MODEL_DIR"
      value: "/net/nfs.cirrascale/allennlp/akshitab/eval_models"
    # This is the location for our perplexity-based eval datasets. In the future, they can be uploaded to huggingface.
    - name: "EVAL_DATA_PATH"
      value: "/net/nfs.cirrascale/allennlp/akshitab/eval_data"
    - name: GDRIVE_SERVICE_ACCOUNT_JSON
      secret: GDRIVE_SERVICE_ACCOUNT_JSON


include_package:
  - evaluation.steps

log_level: info
